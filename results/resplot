#!/usr/bin/env python3
import argparse
import numpy as np
import scipy.integrate as integrate
import scipy.fftpack   as fftpack
import os.path
import sys
import json

import matplotlib
#matplotlib.use('pgf')
import matplotlib.pyplot as plt
from matplotlib import rc, rcParams

# remove or set to True (default) to trigger exception
rc_xelatex = {'pgf.rcfonts': False} 
matplotlib.rcParams.update(rc_xelatex)

rc('text', usetex=True)
rc('font', family='serif')
rcParams.update({'figure.autolayout': True})
    
# Arguments
parser = argparse.ArgumentParser(description='results parser for high-fidelity CFD verification workshop: mesh motion test suite')
parser.add_argument("--plot", action='store_true', default=False, help="Save time-histories to image files.")
parser.add_argument("--time-opacity", action='store_true', default=False, help="Plot time-convergence as opacity.")
parser.add_argument("--save", action='store_true', default=False, help="Plot time-histories to image files.")
parser.add_argument("--use-group-truth", action='store_true', default=False, help="Use groups own truth value (as opposed to a common across all data-sets.)")
parser.add_argument("--geometries", nargs="+", default=[], help="Select geometry configuration(s) for post-processing")
parser.add_argument("--groups", nargs="+", default=[])
parser.add_argument("--motions", nargs="+", default=[])
parser.add_argument("--porders", nargs="+", default=[])
args = parser.parse_args()


# Reference indices
h_list = np.array(['hmm','hm','h0','h1','h2','h3','h4','h5'])
p_list = np.array(['p0','p1','p2','p3','p4','p5','p6'])
t_list = np.array(['t0','t1','t2','t3','t4','t5'])


def main():

    print(" ")
    print(" Data-processing for 2024 High-Fidelity CFD Verification Workshop: ")
    print("     - 6-7 January, 2024")
    print("     - Orlando, FL")
    print("     - Mesh Motion Test suite")
    print(" ----------------------------------------------------------------------")
    print(" ")
    
    
    # Assemble list of geometries to post-process
    geometry_list = []
    if 'Cylinder' in args.geometries or 'all' in args.geometries:
        geometry_list.append('Cylinder')
    if 'Airfoil' in args.geometries or 'all' in args.geometries:
        geometry_list.append('Airfoil')
    

    # Initialize group dictionaries 
    group_dict = {'color':'k',
                  'config':{},    # 'config' is a placeholder that 'Cylinder.json' will be read into
                  'integrals':{'Y-Force':{},
                               'Work':{},
                               'Mass':{},
                               'Mass Error':{}} }
    group_list = []
    if 'UM' in args.groups or 'all' in args.groups:
        group_list.append('UM')
    if 'UCB' in args.groups or 'all' in args.groups:
        group_list.append('UCB')
    if 'AFRL'  in args.groups or 'all' in args.groups:
        group_list.append('AFRL')
    groups = {}
    for g in group_list:
        groups[g] = group_dict.copy()
    

    # Specialize dictionaries for plotting
    if 'UM' in args.groups or 'all' in args.groups:
        groups['UM']['color'] = 'y'
    if 'UCB' in args.groups or 'all' in args.groups:
        groups['UCB']['color'] = 'r'
    if 'AFRL'  in args.groups or 'all' in args.groups:
        groups['AFRL']['color'] = 'b'
    
    # Assemble list of motions to post-process
    motions = []
    if 'M1' in args.motions or 'all' in args.motions:
        motions.append('M1')
    if 'M2' in args.motions or 'all' in args.motions:
        motions.append('M2')




    # Plot time-histories
    hist_figs = []
    for geometry in geometry_list:
        for motion in motions:
            hist_figs.append(plot_time_history(geometry,motion,groups))

    
    # Plot spatial convergence with temporal convergence as opacity
    conv_figs = []
    for geometry in geometry_list:
        for motion in motions:
            conv_figs.append(plot_convergence(geometry,motion,groups))

    if args.plot:
        plt.show()










########################################################
# Helper functions
########################################################

def load_participant_data(group,case,motion,h,p,t):
    """
    Look for participant data file. 
        If found return as numpy array.
        If NOT found, return False
    """
    
    # Load data
    file = f"{group}/{case}-{motion}-{h}-{p}-{t}.txt"
    if (os.path.isfile(file)):
        data = np.loadtxt(file, skiprows=1,delimiter=',',ndmin=2)
    else:
        print(f"| {t} not found",end="")
        #print('Data not found: '+file,end="")
        #print('Data not found: '+file)
        data = False

    return data




def process_data(motion,data):
    """
    Take data that was read-in from a participant data file, process it, and 
    perform some rudimentary validation.

    Return individual time-histories, 
                      end-time-index (in-case last index is used for participant-provided integrated quantities), 
                      and a skip indicator (in-case start/end-time validation failed)
    """


    # Detect participant integrated quantities 
    participant_integrals = None
    if np.isnan(data[-1,0]):
        participant_integrals = {}
        participant_integrals['Y-Force']    = data[-1,1]
        participant_integrals['Work']       = data[-1,2]
        participant_integrals['Mass']       = data[-1,3]
        participant_integrals['Mass error'] = data[-1,4]
        data = np.delete(data,-1,0)



    # Pull out columns from data format
    time           = data[:,0]
    y_force        = data[:,1]
    work_integrand = data[:,2]
    mass           = data[:,3]
    mass_error     = data[:,4]


    # Validate start time
    skip=False
    if not np.isclose(time[0],0.):
        print(f"Start-time for data-set is not 0. Skipping...")
        skip=True

    # Validate stop time
    if motion == 'M1':
        if not np.isclose(time[-1],1.):
            print(f"End-time for data-set is not 1. Skipping...")
            skip=True
    elif motion == 'M2':
        if not np.isclose(time[-1],40.):
            print(f"End-time for data-set is not 40. Skipping...")
            skip=True

    return time,y_force,work_integrand,mass,mass_error,participant_integrals,skip




def get_config_hindices(config):
    """
    Take configuration dictionary read in from either Airfoil.json or Cylinder.json
    and detect 'h'-indices included in data-set.
    """
    _case_hs = []
    for h in h_list:
        if h in config:
            _case_hs.append(h)

    if _case_hs is None:
        print("No 'h'-index descriptors detected in data set json configuration.")
        sys.exit()

    return _case_hs

def get_config_pindices(config):
    """
    Take configuration dictionary read in from either Airfoil.json or Cylinder.json
    and detect 'p'-indices included in data-set.
    """
    _case_ps = []
    for p in p_list:
        if p in config:
            _case_ps.append(p)

    if _case_ps is None:
        print("No 'p'-index descriptors detected in data set json configuration.")
        sys.exit()

    return _case_ps


def get_config_tindices(config):
    """
    Take configuration dictionary read in from either Airfoil.json or Cylinder.json
    and detect 't'-indices included in data-set.
    """
    _case_ts = []
    for t in t_list:
        if t in config:
            _case_ts.append(t)

    if _case_ts is None:
        print("No 't'-index descriptors detected in data set json configuration.")
        sys.exit()

    return _case_ts


def get_hmax(config):
    """
    Take configuration dictionary read in from either Airfoil.json or Cylinder.json
    and detect max 'h'-index included in data-set.
    """
    max_h = None
    for h in reversed(h_list):
        if h in config:
            max_h = h
            break

    if max_h is None:
        print("No 'h'-index descriptors detected in data set json configuration.")
        sys.exit()

    return max_h

def get_pmax(config):
    """
    Take configuration dictionary read in from either Airfoil.json or Cylinder.json
    and detect max 'p'-index included in data-set.
    """
    max_p = None
    for p in reversed(p_list):
        if p in config:
            max_p = p
            break

    if max_p is None:
        print("No 'p'-index descriptors detected in data set json configuration.")
        sys.exit()

    return max_p

def get_tmax(group,geometry,motion):
    """
    Look at files in contributed data set for given <group,geometry> and
    detect the maximum 't'-index submitted.
    """
    # Return all files in submission directory
    files = os.listdir(f"{group}")

    # Check for t_list entries in file name
    max_t = '0'
    for file in files:
        # Check if file include geometry and is a data file (.txt)
        if (geometry in file) and (motion in file) and ('.txt' in file):
            for t in reversed(t_list):
                # Update max_t if higher t was found in file name
                if (t in file) and (t > max_t):
                    max_t = t
                    break

    return max_t


def get_tmax_from_list(case_ts,ref_ts):
    """
    For incoming list of t-indices case_ts, find the max in the list of ref_ts
    """

    # For each 't' in case_ts, find its index in ref_ts
    tmax_index = -1
    tmax = ''
    for t in case_ts:
        ind = np.where(ref_ts==t)[0][0]
        if ind > tmax_index:
            tmax_index = ind
            tmax = t
    return tmax, tmax_index




def get_case_tindices(group,geometry,motion,h,p):
    """
    Look at files in contributed data set for given <group,geometry,h,p> and
    detect the 't'-indices submitted.
    """
    # Return all files in submission directory
    files = os.listdir(f"{group}")

    # Check for t_list entries in file name
    case_ts = []
    for file in files:
        # Check if file include geometry and is a data file (.txt)
        if (geometry in file) and (motion in file) and (h in file) and (p in file) and ('.txt' in file):
            for t in reversed(t_list):
                # Update max_t if higher t was found in file name
                if (t in file):
                    case_ts.append(t)
    return case_ts








def display_time_convergence(geometries,groups,motions):
    """ Compute differences in quantities from one time-level to the next.

    Differences in integrated quantities for varying time-resolution
        - Computed as: (Current Time-Resolution) - (Previous Time-Resolution)
        - First value in row is total integral for smallest time-resolution

    """

    for geometry in geometries:
        for group in groups:
            print(" ")
            print(group)
            print("....................................................................")
            for motion in motions:
        
                # Read data-set configuration
                f = open(f"{group}/{geometry}.json")
                groups[group]['config'] = json.load(f)
        
                # Get resolutions
                hmax = get_hmax(groups[group]['config'])
                hmax_index = np.where(h_list==hmax)[0][0]
        
                pmax = get_pmax(groups[group]['config'])
                pmax_index = np.where(p_list==pmax)[0][0]
        
                for h in h_list[0:hmax_index+1]:
                    for p in p_list[0:pmax_index+1]:
                        print(f"{h},{p}: ",end="")
        
                        tmax = get_tmax(group,geometry,motion)
                        tmax_index = np.where(t_list==tmax)[0][0]
                        prev = 0.
                        for t in t_list[0:tmax_index+1]:
        
                            # Load max-resolution data
                            data = load_participant_data(group,geometry,motion,h,p,t)
        
                            # Plot time-histories
                            if isinstance(data, np.ndarray):
                                time,y_force,work_integrand,mass,mass_error,participant_integrals,skip = process_data(motion,data)
                                if not skip:
                                    integral = integrate.simps(y=y_force,x=time)
                                    diff = integral - prev
                                    print(diff,end="")
                                    print(", ",end="")
                                    prev = integral
                                else:
                                    print(" Incomplete ",end="")
                            else:
                                print(', ',end="")
        
                        print("")




def plot_convergence(geometry,motion,groups):
    """ Compute differences in quantities from one time-level against a reference 
        space,time-resolved case. Plot spatial convergence. Plot time convergence as opacity variances.

        Integrated quantities for varying time-resolution compared against reference h,t-resolved result
        - Computed as: (Reference Time-Resolution) - (Current Time-Resolution)")
    """
    
    # Create figure
    #fig = plt.figure(figsize=(16,4))
    fig = plt.figure(figsize=(18,4))
    fig.set_facecolor('White')
    axes = [fig.add_subplot(141), fig.add_subplot(142), fig.add_subplot(143), fig.add_subplot(144)]





    for group in groups:
    
        # Read data-set configuration
        f = open(f"{group}/{geometry}.json")
        groups[group]['config'] = json.load(f)
        color = groups[group]['color']


        # Select + compute reference/truth quantities
        if geometry == 'Cylinder':

            # Compute integrated reference quantities
            if args.use_group_truth:
                
                # Get groups own reference/truth data-set
                ref_h = groups[group]['config']['reference']['h']
                ref_p = groups[group]['config']['reference']['p']
                ref_t = groups[group]['config']['reference']['t']

                # Compute dof count
                ndof_max = groups[group]['config'][ref_h] * groups[group]['config'][ref_p]

                # Load max-resolution data
                data = load_participant_data(group,geometry,motion,ref_h,ref_p,ref_t)

                time,y_force,work_integrand,mass,mass_error,participant_integrals,skip = process_data('M1',data)
                ref_yforce        = integrate.simps(y=y_force,       x=time)
                ref_work          = integrate.simps(y=work_integrand,x=time)
                ref_mass          = integrate.simps(y=mass,          x=time)
                
            else:
                # Load max-resolution data
                #data = load_participant_data('UM','Cylinder','M1',h='h3',p='p4',t='t4')
                data = load_participant_data('UCB','Cylinder','M1',h='h5',p='p3',t='t6')
                time,y_force,work_integrand,mass,mass_error,participant_integrals,skip = process_data('M1',data)
                ref_yforce        = integrate.simps(y=y_force,       x=time)
                ref_work          = integrate.simps(y=work_integrand,x=time)
                ref_mass          = integrate.simps(y=mass,          x=time)
                
                # Compute analytical (exact) reference mass
                volume  = np.pi*0.5*0.5
                density = 1.
                ref_mass = volume * density



        elif geometry == 'Airfoil':
            print("Airfoil reference data undefined")
            sys.exit()


        # Get resolutions
        hs = get_config_hindices(groups[group]['config'])
        ts = get_config_tindices(groups[group]['config'])
        ps = get_config_pindices(groups[group]['config'])

        # Only use valid ps from prescribed porders if they are prescribed
        ps_list = []
        if len(args.porders) > 0 :
            for p in ps:
                if p in args.porders:
                    ps_list.append(p)
            ps = ps_list

        error_yforce  = np.zeros((len(hs),len(ps),len(ts)))
        error_yforce0 = np.zeros((len(hs),len(ps),len(ts)))
        error_work    = np.zeros((len(hs),len(ps),len(ts)))
        error_mass    = np.zeros((len(hs),len(ps),len(ts)))
        ndof          = np.zeros((len(hs),len(ps)))

        # Populate with NaNs so not plotted if not filled with actual error data
        error_yforce[:,:,:]  = np.nan
        error_work[:,:,:]    = np.nan
        error_mass[:,:,:]    = np.nan
        error_yforce0[:,:,:] = np.nan

        for hi,h in enumerate(hs):
            for pi,p in enumerate(ps):

                # For a given h,p-index, are there multiple t-index results
                case_ts = get_case_tindices(group,geometry,motion,h,p)
                tmax, tmax_index = get_tmax_from_list(case_ts,t_list)

                # Compute dof count
                ndof[hi,pi] = groups[group]['config'][h] * groups[group]['config'][p]

                for ti,t in enumerate(ts):
                    # Load max time-resolution data
                    data = load_participant_data(group,geometry,motion,h=h,p=p,t=t)
                    if isinstance(data, np.ndarray):
                        time,y_force,work_integrand,mass,mass_error,participant_integrals,skip = process_data(motion,data)
                        if not skip:
                            yforce_integral = integrate.simps(y=y_force,       x=time)
                            work_integral   = integrate.simps(y=work_integrand,x=time)
                            mass_integral   = integrate.simps(y=mass,          x=time)

                            error_yforce[hi,pi,ti]  = ref_yforce - yforce_integral
                            error_work[hi,pi,ti]    = ref_work   - work_integral   
                            error_mass[hi,pi,ti]    = ref_mass   - mass_integral
                            error_yforce0[hi,pi,ti] = y_force[0]

        symbols = {'p1':'o','p2':'^','p3':'s','p4':'p'}
        for pi,p in enumerate(ps):
            symbol = symbols[p]
            axes[0].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_yforce[ :,pi,-1]),symbol+color+'-',label=f"{group}: {p}",linewidth=1.0)
            axes[1].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_work[   :,pi,-1]),symbol+color+'-',label=f"{group}: {p}",linewidth=1.0)
            axes[2].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_mass[   :,pi,-1]),symbol+color+'-',label=f"{group}: {p}",linewidth=1.0)
            axes[3].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_yforce0[:,pi,-1]),symbol+color+'-',label=f"{group}: {p}",linewidth=1.0)
            if args.time_opacity:
                itime_end = -2
                alpha_plot = 0.9
                while itime_end >= -len(ts):
                    axes[0].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_yforce[ :,pi,itime_end]),symbol+color+'--',markerfacecolor='none',linewidth=1.0,alpha=alpha_plot)
                    axes[1].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_work[   :,pi,itime_end]),symbol+color+'--',markerfacecolor='none',linewidth=1.0,alpha=alpha_plot)
                    axes[2].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_mass[   :,pi,itime_end]),symbol+color+'--',markerfacecolor='none',linewidth=1.0,alpha=alpha_plot)
                    axes[3].loglog(1./np.sqrt(ndof[:,pi]),np.abs(error_yforce0[:,pi,itime_end]),symbol+color+'--',markerfacecolor='none',linewidth=1.0,alpha=alpha_plot)
                    itime_end -= 1
                    alpha_plot -= 0.1

    axes[0].legend()
    axes[1].legend()
    axes[2].legend()
    axes[3].legend()
    axes[0].set_xlabel(r'$1/\sqrt{\mathrm{nDOF}}$')
    axes[1].set_xlabel(r'$1/\sqrt{\mathrm{nDOF}}$')
    axes[2].set_xlabel(r'$1/\sqrt{\mathrm{nDOF}}$')
    axes[3].set_xlabel(r'$1/\sqrt{\mathrm{nDOF}}$')
    axes[0].set_ylabel(r'$|\mathrm{YImpulse}_{\mathrm{ref}} -  \mathrm{YImpulse}|$')
    axes[1].set_ylabel(r'$|\mathrm{Work}_{\mathrm{ref}} -  \mathrm{Work}|$')
    axes[2].set_ylabel(r'$|\mathrm{Mass}_{\mathrm{ref}} -  \mathrm{Mass}|$')
    axes[3].set_ylabel(r'$|\mathrm{YForce}_{t=0}|$')

    axes[0].set_xlim((2.e-4,0.e-0))
    axes[1].set_xlim((2.e-4,0.e-0))
    axes[2].set_xlim((2.e-4,0.e-0))
    axes[3].set_xlim((2.e-4,0.e-0))



    if args.save:
        fig.savefig(f'{geometry}_{motion}_Convergence.png', bbox_inches='tight', dpi=800)

    return fig



def plot_time_history(geometry,motion,groups):

    # Create figure
    fig = plt.figure(figsize=(16,4))
    fig.set_facecolor('White')
    axes = [fig.add_subplot(141), fig.add_subplot(142), fig.add_subplot(143), fig.add_subplot(144)]


    # Plot time-histories
    print(" ")
    print(" ")
    print(" Reference fine-space (h,p,t) integrated quantities")
    print(" ======================================================================")
    for group in groups:

        # Read data-set configuration
        f = open(f"{group}/{geometry}.json")
        groups[group]['config'] = json.load(f)

        # Get max resolution
        hmax = groups[group]['config']['reference']['h']
        pmax = groups[group]['config']['reference']['p']
        tmax = groups[group]['config']['reference']['t']

        # Compute dof count
        ndof_max = groups[group]['config'][hmax] * groups[group]['config'][pmax]

        # Load max-resolution data
        data = load_participant_data(group,geometry,motion,hmax,pmax,tmax)

        # Plot time-histories
        if isinstance(data, np.ndarray):
            time,y_force,work_integrand,mass,mass_error,participant_integrals,skip = process_data(motion,data)

            if not skip: 
                groups[group]['integrals']['Y-Force'] = integrate.simps(y=y_force,        x=time)
                groups[group]['integrals']['Work']    = integrate.simps(y=work_integrand, x=time)
                groups[group]['integrals']['Mass']    = integrate.simps(y=mass,           x=time)

                print(" ")
                print(f"{group}: {hmax},{pmax},{tmax})")
                print("....................................................................")
                print('Y-Force', groups[group]['integrals']['Y-Force'])
                print('Work',    groups[group]['integrals']['Work'])
                print('Mass',    groups[group]['integrals']['Mass'])

                color = groups[group]['color']
                axes[0].plot(time,y_force,        color+'--',linewidth=1.0,label=f"{group}: {hmax}-{pmax}-{tmax}")
                axes[1].plot(time,work_integrand, color+'--',linewidth=1.0,label=f"{group}: {hmax}-{pmax}-{tmax}")
                axes[2].plot(time,mass,           color+'--',linewidth=1.0,label=f"{group}: {hmax}-{pmax}-{tmax}")
                axes[3].plot(time,mass_error,     color+'--',linewidth=1.0,label=f"{group}: {hmax}-{pmax}-{tmax}")

        else:
            # End line
            print("")


    axes[0].legend()
    axes[1].legend()
    axes[2].legend()
    axes[3].legend()
    
    axes[0].set_xlabel('Time')
    axes[1].set_xlabel('Time')
    axes[2].set_xlabel('Time')
    axes[3].set_xlabel('Time')
    
    axes[0].set_ylabel('Force-Y')
    axes[1].set_ylabel('Work integrand')
    axes[2].set_ylabel('Mass')
    axes[3].set_ylabel('Mass error')
    
    axes[0].set_xlim((0.,1.))
    axes[1].set_xlim((0.,1.))
    axes[2].set_xlim((0.,1.))
    axes[3].set_xlim((0.,1.))

    if args.save:
        fig.savefig(f'{geometry}_{motion}_Histories.png', bbox_inches='tight', dpi=800)

    return fig

            




if __name__ == '__main__':
    main()
